{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaac2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from vllm import LLM\n",
    "from vllm.sampling_params import SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c76d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"http://localhost:8000/v1\"\n",
    "MODEL = \"sapienzanlp/Minerva-7B-instruct-v1.0\"\n",
    "# MODEL = \"sapienzanlp/Minerva-3B-base-v1.0\"\n",
    "\n",
    "sampling_params = SamplingParams(max_tokens=1024)\n",
    "\n",
    "DATA_DIR = \"../multiloko_eval/dev.jsonl\"\n",
    "\n",
    "output_file = \"../model_output/minerval/7b_instruct/dev.jsonl\"\n",
    "# output_dir = os.path.dirname(output_file)\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.makedirs(output_dir)\n",
    "\n",
    "output_eval_path = \"../model_output/minerval/7b_instruct/evaluate.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ef8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(model=MODEL,device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a71eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def data_loader(input_file):\n",
    "    '''read data from input_file, the data inside the file is a multi-line jsonl file, an example line as following:\n",
    "    {\"text\": \"Storia 2011 ...\", \"question\": \"Quando Ã¨ stato lanciato il TG Norba 24?\", \"target\": \"TG ...\", \"id\": \"004_tg_norba_24.txt\", \"targets\": [\"2010-10-25\", \"venticinque ottobre duemiladieci\", \"25 ottobre 2010\", \"25/10/2010\"], \"output_type\": \"una data\"}\n",
    "    save \"id\", \"question\", \"targets\" and \"output_type\" to a dict, use \"id\" as the key\n",
    "    return a dict, the key is \"id\" and the value is a dict with \"question\", \"targets\" and \"output_type\"\n",
    "    '''\n",
    "\n",
    "    data_dict = {}\n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            entry = json.loads(line.strip())\n",
    "            data_dict[entry['id']] = {\n",
    "                'question': entry['question'],\n",
    "                'targets': entry['targets'],\n",
    "                'output_type': entry['output_type']\n",
    "            }\n",
    "    return data_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcaaf4b",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "data_dict = data_loader(DATA_DIR)\n",
    "\n",
    "responses = {}\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    for entry_id, entry in data_dict.items():\n",
    "        question = entry['question']\n",
    "        output_type = entry['output_type']\n",
    "        massages = f\"Rispondi alla seguente domanda in modo chiaro e conciso: {question} Produci solo risposte del seguente tipo: {output_type}.\"\n",
    "        response = llm.generate(massages)\n",
    "        response_text = response[0].outputs[0].text\n",
    "\n",
    "        # Save the response to the file\n",
    "        output_entry = {\n",
    "            \"id\": entry_id,\n",
    "            \"question\": question,\n",
    "            \"response\": response_text,\n",
    "            \"targets\": entry['targets'],\n",
    "            \"output_type\": output_type,\n",
    "            \"massages\": massages,\n",
    "        }\n",
    "        file.write(json.dumps(output_entry, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d27dafc",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_eval(path, output_eval_path):\n",
    "    '''\n",
    "    read the output file and prepare the evaluation data\n",
    "    the output file is a jsonl file\n",
    "    an example of the output file:\n",
    "    {\"id\": \"1\", \"question\": \"What is the capital of France?\", \"response\": \"Paris\", \"targets\": [\"Paris\"], \"output_type\": \"text\", \"massages\": \"Rispondi alla seguente domanda in modo chiaro e conciso: What is the capital of France? Produci solo risposte del seguente tipo: text.\"}\n",
    "    write the eval data also into a new jsonl file\n",
    "    an example of the eval data:\n",
    "    {\"language\": \"language\", \"id\" : \"id\", \"prediction\": \"prediction\"}\n",
    "    '''\n",
    "    eval_data = []\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            entry = json.loads(line.strip())\n",
    "            eval_entry = {\n",
    "                \"language\": \"italian\",  # Assuming the language is Italian based on the context\n",
    "                \"id\": entry[\"id\"],\n",
    "                \"prediction\": entry[\"response\"]\n",
    "            }\n",
    "            eval_data.append(eval_entry)\n",
    "    \n",
    "    # Write the eval data to a new jsonl file\n",
    "    with open(output_eval_path, 'w', encoding='utf-8') as eval_file:\n",
    "        for eval_entry in eval_data:\n",
    "            eval_file.write(json.dumps(eval_entry, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205e0420",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "prepare_eval(output_file, output_eval_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semeval_ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
