{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85b3a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import argparse\n",
    "import re\n",
    "import string\n",
    "\n",
    "import sacrebleu\n",
    "import editdistance\n",
    "\n",
    "from typing import Dict, List, Tuple, Any, Union\n",
    "from collections import Counter\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d85d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../multiloko_eval/dev.jsonl\"\n",
    "\n",
    "MODEL = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "model_f = MODEL.split(\"/\")[0]\n",
    "model_name = MODEL.split(\"/\")[1]\n",
    "\n",
    "prediction_path = os.path.join(\n",
    "    \"../model_output\", \n",
    "    model_f, \n",
    "    model_name,\n",
    "    \"evaluate_5shot.jsonl\"\n",
    ")\n",
    "\n",
    "out_file = os.path.join(\n",
    "    \"../model_output\", \n",
    "    model_f, \n",
    "    model_name,\n",
    "    \"evaluate_results_5shot.jsonl\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3740e242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_articles(text: str) -> str:\n",
    "    return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9939b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_space_fix(text: str) -> str:\n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2af425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes the punctuation from a string. This used to rely on the builtin string.punctuation constant\n",
    "    which contains these symbols: !\"#$%&'()*+,-.:;<=>?@[]^_`{|}~ but it completely misses CJK punctuation or\n",
    "    some western european language' variations.\n",
    "    \"\"\"\n",
    "    punct = string.punctuation  # Sadly the builtin punctuation is exclusive to ASCII\n",
    "    # Adapted from https://stackoverflow.com/questions/36640587/how-to-remove-chinese-punctuation-in-python\n",
    "    extra_punct = r\"\"\"„“«»¡¿《》！？｡。＂＃＄％＆＇（）＊＋，－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､、〃》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏.\"\"\"\n",
    "    punct = punct + extra_punct\n",
    "    exclude = set(punct)\n",
    "    return \"\".join(ch for ch in text if ch not in exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8021035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(text: str) -> str:\n",
    "    return white_space_fix(remove_articles(remove_punc(text.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "612f2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_answers(input: Union[str, List[str]]) -> Union[str, List[str]]:\n",
    "    if isinstance(input, str):\n",
    "        return normalize_answer(input)\n",
    "    else:\n",
    "        return [normalize_answer(x) for x in input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9356d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input_jsonl(file_and_lang: List[Tuple[str, str]]) -> Dict[str, Dict[str, List[str]]]:\n",
    "    # parses the input jsonl file(s)\n",
    "    # It saves only the id and the true answer ret'language'] = []\n",
    "    ret = {}\n",
    "    for filename, language in file_and_lang:\n",
    "        ret[language] = {}\n",
    "        with open(filename, \"r\") as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                ret[language][data[\"id\"]] = postprocess_answers(data[\"targets\"])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b86ae33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_output_jsonl(filename: str) -> Dict[str, Dict[str, str]]:\n",
    "    # Parses a JSONl file. Expected format is\n",
    "    # {\"language\": \"language\", \"id\" : \"id\", \"prediction\": \"prediction\"}\n",
    "    ret = {}\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            assert \"language\" in data\n",
    "            assert \"id\" in data\n",
    "            assert \"prediction\" in data\n",
    "            assert data[\"language\"] != \"\"\n",
    "            assert data[\"id\"] != \"\"\n",
    "            if data[\"language\"] not in ret:\n",
    "                ret[data[\"language\"]] = {}\n",
    "            ret[data[\"language\"]][data[\"id\"]] = postprocess_answers(data[\"prediction\"])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66e12388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_results(results: Dict[str, Any], output_file: Union[str, None]) -> None:\n",
    "    if output_file:\n",
    "        with open(output_file, \"w\") as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "    else:\n",
    "        print(json.dumps(results), ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca2edf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(prediction: str, targets: List[str]) -> float:\n",
    "    def _f1(pred_tokens: List[str], gt_tokens: List[str]) -> float:\n",
    "        common = Counter(pred_tokens) & Counter(gt_tokens)\n",
    "        num_same = sum(common.values())\n",
    "        if num_same == 0:\n",
    "            return 0\n",
    "        precision = 1.0 * num_same / len(pred_tokens)\n",
    "        recall = 1.0 * num_same / len(gt_tokens)\n",
    "        return (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    return max(_f1(prediction.split(), target.split()) for target in targets)\n",
    "\n",
    "\n",
    "def exact_match(prediction: str, targets: List[str]) -> float:\n",
    "    return max(float(prediction == target) for target in targets)\n",
    "\n",
    "\n",
    "def sentence_bleu(prediction: str, targets: List[str], **kwargs: Any) -> float:\n",
    "    return sacrebleu.sentence_bleu(prediction, targets, **kwargs).score\n",
    "\n",
    "\n",
    "def sentence_chrf(prediction: str, targets: List[str], **kwargs: Any) -> float:\n",
    "    return sacrebleu.sentence_chrf(prediction, targets, **kwargs).score\n",
    "\n",
    "\n",
    "def edit_distance(prediction_tokens: str, target_tokens: str) -> float:\n",
    "    \"\"\"\n",
    "    Get minimum edit distance (Levenshtein distance) between prediction and target\n",
    "    \"\"\"\n",
    "    return float(editdistance.eval(prediction_tokens, target_tokens))\n",
    "\n",
    "\n",
    "def edit_distance_many(prediction_tokens: str, target_tokens: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    Get minimum edit distance (Levenshtein distance) between prediction and\n",
    "    multiple possible targets.\n",
    "    \"\"\"\n",
    "    return float(\n",
    "        min(edit_distance(prediction_tokens, target) for target in target_tokens)\n",
    "    )\n",
    "\n",
    "\n",
    "def edit_similarity(prediction: str, targets: List[str]) -> float:\n",
    "    return max(SequenceMatcher(None, prediction, target).ratio() for target in targets)\n",
    "\n",
    "\n",
    "def evaluate_all(reference_answers, our_answers):\n",
    "    # Evaluate all metrics\n",
    "    metrics = {\n",
    "        \"em\": exact_match,\n",
    "        \"f1\": f1,\n",
    "        \"bleu\": sentence_bleu,\n",
    "        \"chrf\": sentence_chrf,\n",
    "        \"edit_distance\": edit_distance_many,\n",
    "        \"edit_similarity\": edit_similarity,\n",
    "    }\n",
    "    # Compute per example scores\n",
    "    results = {}\n",
    "    for lang, examples in our_answers.items():\n",
    "        results[lang] = {}\n",
    "        ref_current = reference_answers[lang]\n",
    "        for id, prediction in examples.items():\n",
    "            results[lang][id] = {}\n",
    "            targets = ref_current[id]\n",
    "            for metric_name, metric in metrics.items():\n",
    "                results[lang][id][metric_name] = metric(prediction, targets)\n",
    "            results[lang][id][\"targets\"] = targets\n",
    "            results[lang][id][\"prediction\"] = prediction\n",
    "        # Now compute aggregate scores for that language\n",
    "        for metric in metrics:\n",
    "            count = 0\n",
    "            mysum = 0\n",
    "            for id in results[lang]:\n",
    "                if id in metrics:\n",
    "                    continue\n",
    "                mysum += results[lang][id][metric]\n",
    "                count += 1\n",
    "            results[lang][metric] = mysum / count\n",
    "    # Now compute across all languages\n",
    "    results[\"group_metrics\"] = {}\n",
    "    for metric in metrics:\n",
    "        results[\"group_metrics\"][f\"average_{metric}\"] = sum(results[lang][metric] for lang in results if lang != \"group_metrics\") / (len(results) - 1)\n",
    "        results[\"group_metrics\"][f\"max_{metric}\"] = max(results[lang][metric] for lang in results if lang != \"group_metrics\")\n",
    "        results[\"group_metrics\"][f\"min_{metric}\"] = min(results[lang][metric] for lang in results if lang != \"group_metrics\")\n",
    "        results[\"group_metrics\"][f\"gap_{metric}\"] = results[\"group_metrics\"][f\"max_{metric}\"] - results[\"group_metrics\"][f\"min_{metric}\"]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2320afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_parse_tuples = [(DATA_DIR, \"italian\"),]\n",
    "predictions = prediction_path\n",
    "output = out_file\n",
    "reference_answers = parse_input_jsonl(input_parse_tuples)\n",
    "our_answers = parse_output_jsonl(predictions)\n",
    "results = evaluate_all(reference_answers, our_answers)\n",
    "output_results(results, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiloko_minerval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
